# AI Interpretability Learning Journey

## Description
Hi there! I'm diving into the world of AI interpretability, and this repo is my digital notebook. 

AI technology has been growing at an exponential speed, especially since the launch of ChatGPT. However, as the initial hype is starting to settle, we're beginning to understand the crucial importance of reliability in AI systems. A key aspect of this reliability is AI interpretability.

My goal is to explore how we can make AI models more transparent and explainable.

Here's what I plan to do in this repo:
- Share my notes and summaries from papers I read
- Document my experiments and projects related to AI interpretability
- Track my progress and insights as I learn

I believe that by improving our understanding of AI interpretability, we can contribute to the development of more reliable, trustworthy, and effective AI systems.

## Current Focus: ARENA Program
I am currently following the **ARENA program** by Callum McDougall, which is an amazing resource for exploring the mechanisms behind transformer interpretability. You can check it out [here](https://arena3-chapter1-transformer-interp.streamlit.app/).

As part of this learning journey, I work on projects that help me gain hands-on experience with transformer interpretability. 

## Projects
For now, Iâ€™ve worked on projects about **transformer circuits**, exploring how transformers solve tasks and understanding their internal mechanisms. These projects are a stepping stone as I build depth in the field. 

### Transformer Circuits Projects
- **Find-Min**: Similar to the Find-Median project, but aimed at understanding how transformers learn to compute the minimum value in a sequence.
- **Find-Median**: A project focused on teaching a transformer to compute the median of a sequence, analyzing its attention mechanisms and outputs.

I plan to expand this section with more projects as I gain deeper insights into interpretability.

## Resources
I will include resources that I use to guide my learning. This will include videos, papers, blog posts, and interactive tools that I find helpful.

## Get in Touch
I'm always eager to learn more! If you have suggestions, questions, or want to discuss AI interpretability, please feel free to:
- Open an issue in this repo
- Reach out to me on [your preferred platform, e.g., Twitter, LinkedIn](https://linktr.ee/ismailko)
- Send me an email at [your email if you're comfortable sharing](mailto:i_konak@hotmail.com)

Your insights and feedback are greatly appreciated!
